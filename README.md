# CDN Go - Projet de Content Delivery Network

Ce projet impl√©mente un Content Delivery Network (CDN) en Go, con√ßu pour optimiser la distribution de contenu web avec des fonctionnalit√©s avanc√©es de mise en cache, de r√©partition de charge et de monitoring.

## üöÄ Fonctionnalit√©s

- **Proxy HTTP** : Redirection intelligente des requ√™tes
- **Syst√®me de Cache** :
  - Cache LRU en m√©moire
  - Support Redis pour le cache distribu√©
- **Load Balancing** :
  - Round Robin
  - Weighted Round Robin
  - Least Connections
- **S√©curit√©** :
  - Rate Limiting
  - Protection DDoS
  - Headers de s√©curit√© HTTP
- **Monitoring** :
  - M√©triques Prometheus
  - Visualisation Grafana
  - Logging structur√© avec Logrus

## üõ† Pr√©requis

- Docker
- Docker Compose
- Go 1.23+ (pour le d√©veloppement local)

## üö¶ D√©marrage

1. **Mode D√©veloppement** :

```bash
docker compose up app-dev
```

- Hot-reload activ√©
- Accessible sur http://localhost:8080
- M√©triques sur http://localhost:8080/metrics

2. **Mode Production** :

```bash
docker compose up app-prod
```

- Optimis√© pour la production
- Accessible sur http://localhost:8081
- M√©triques sur http://localhost:8081/metrics

3. **Services additionnels** :

- Grafana : http://localhost:3000 (admin/admin)
- Prometheus : http://localhost:9090
- Redis : localhost:6379

## üèó Structure du Projet

```
app/
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ cache/          # Impl√©mentation du cache (LRU, Redis)
‚îÇ   ‚îú‚îÄ‚îÄ loadbalancer/   # Algorithmes de load balancing
‚îÇ   ‚îî‚îÄ‚îÄ middleware/     # Middlewares (s√©curit√©, m√©triques)
‚îú‚îÄ‚îÄ pkg/
‚îÇ   ‚îî‚îÄ‚îÄ config/         # Configuration de l'application
‚îî‚îÄ‚îÄ main.go            # Point d'entr√©e de l'application
```

## üîç Fonctionnement D√©taill√©

### 1. Syst√®me de Cache

- **Cache LRU** (`internal/cache/cache.go`) :
  - Impl√©mente l'interface `Cache`
  - Utilise `hashicorp/golang-lru` pour la gestion du cache en m√©moire
  - Limite configurable de la taille du cache
  - Cache uniquement les requ√™tes GET
  - TTL configurable pour les entr√©es du cache

- **Endpoints de Gestion du Cache** :
  - `POST /cache/purge` : Vide compl√®tement le cache
    ```bash
    # Exemple d'utilisation
    curl -X POST http://localhost:8080/cache/purge
    ```

### 2. Load Balancer

- **Impl√©mentations** (`internal/loadbalancer/loadbalancer.go`) :
  - `RoundRobin` : Distribution cyclique des requ√™tes
  - `WeightedRoundRobin` : Distribution pond√©r√©e selon la capacit√© des serveurs
  - `LeastConnections` : Envoi vers le serveur le moins charg√©

### 3. Endpoints API

#### Backend Service (port 8080)
- **Authentification** :
  - `POST /register` : Inscription d'un nouvel utilisateur
  - `POST /login` : Connexion utilisateur

- **Gestion des Fichiers** (requiert authentification) :
  - `POST /api/files` : Upload d'un fichier
  - `GET /api/files/:id` : R√©cup√©ration d'un fichier
  - `DELETE /api/files/:id` : Suppression d'un fichier

- **Gestion des Dossiers** (requiert authentification) :
  - `POST /api/folders` : Cr√©ation d'un dossier
  - `GET /api/folders/:id` : Liste du contenu d'un dossier
  - `DELETE /api/folders/:id` : Suppression d'un dossier

- **Health Check** :
  - `GET /health` : V√©rification de l'√©tat du service

#### CDN Service (port 8080)
- **Cache** :
  - `POST /cache/purge` : Vide le cache
  - Note : Seules les requ√™tes GET sont mises en cache

- **Monitoring** :
  - `GET /metrics` : M√©triques Prometheus
  - `GET /health` : √âtat du CDN
  - `GET /ready` : V√©rification de disponibilit√©

### 4. Monitoring

- **M√©triques** :
  - Temps de r√©ponse des requ√™tes
  - Nombre de requ√™tes par endpoint
  - Taux de succ√®s/erreur
  - Utilisation du cache

- **Visualisation dans Grafana** via Prometheus

### 5. Application Principale

Le fichier `main.go` orchestre tous ces composants :

1. Initialise le logger et le cache
2. Configure le load balancer
3. Met en place les middlewares de s√©curit√© et monitoring
4. D√©marre le serveur HTTP avec gestion gracieuse de l'arr√™t

## üìä Monitoring

### M√©triques disponibles :

- `http_duration_seconds` : Temps de r√©ponse des requ√™tes
- `http_requests_total` : Nombre total de requ√™tes par endpoint
- Visualisation dans Grafana via Prometheus

## üîí S√©curit√©

- Rate limiting : 100 requ√™tes/seconde par d√©faut
- Headers de s√©curit√© :
  - `X-Frame-Options`
  - `X-Content-Type-Options`
  - `X-XSS-Protection`
  - `Content-Security-Policy`
  - `Strict-Transport-Security`

## ü§ù Contribution

1. Fork le projet
2. Cr√©ez votre branche (`git checkout -b feature/amazing-feature`)
3. Committez vos changements (`git commit -m 'Add amazing feature'`)
4. Push vers la branche (`git push origin feature/amazing-feature`)
5. Ouvrez une Pull Request

## üöÄ D√©ploiement sur AWS EKS

### Pr√©requis AWS

- Un compte AWS avec les droits n√©cessaires
- AWS CLI configur√©
- `eksctl` install√©
- `kubectl` install√©

### 1. Construction de l'Image Docker

```bash
# Construction de l'image
docker build -t misterzapp/goofy-cdn:latest -f docker/cdn/Dockerfile .

# Push vers Docker Hub
docker push misterzapp/goofy-cdn:latest
```

### 2. D√©ploiement sur EKS

#### Cr√©ation du Cluster

```bash
# Cr√©ation du cluster EKS
eksctl create cluster \
  --name goofy-cdn-cluster \
  --region eu-west-3 \
  --nodegroup-name goofy-cdn-workers \
  --node-type t3.small \
  --nodes 2 \
  --nodes-min 1 \
  --nodes-max 3
```

#### D√©ploiement de l'Application

```bash
# D√©ployer l'application
kubectl apply -f k8s/cdn-deployment.yaml
kubectl apply -f k8s/cdn-service.yaml

# V√©rifier le d√©ploiement
kubectl get pods
kubectl get services
```

### 3. Gestion des Ressources

#### V√©rification des Ressources

```bash
# Lister les n≈ìuds
kubectl get nodes

# Lister les pods
kubectl get pods --all-namespaces

# Voir les logs
kubectl logs -l app=goofy-cdn
```

#### Nettoyage des Ressources

```bash
# Supprimer le nodegroup
eksctl delete nodegroup --cluster goofy-cdn-cluster --name goofy-cdn-workers

# Supprimer le cluster complet (arr√™te toute facturation)
eksctl delete cluster --name goofy-cdn-cluster
```

### 4. Co√ªts AWS √† Surveiller

- Cluster EKS : ~$0.10 par heure
- N≈ìuds EC2 (t3.small) : ~$0.023 par heure par n≈ìud
- Load Balancer : ~$0.025 par heure
- Volumes EBS et ENI : co√ªts variables selon l'utilisation

‚ö†Ô∏è **Important** : Pensez √† supprimer toutes les ressources apr√®s utilisation pour √©viter des co√ªts inutiles.

### 5. Troubleshooting Courant

#### Probl√®mes de CNI ( a voir car probl√®me pour l'instant)

Si les pods restent en √©tat "ContainerCreating" :

```bash
# R√©installer le CNI Amazon VPC
kubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/v1.12.6/config/master/aws-k8s-cni.yaml

# Red√©marrer les pods CNI
kubectl delete pods -n kube-system -l k8s-app=aws-node
```

#### Probl√®mes de Permissions

V√©rifier que le r√¥le IAM a les bonnes politiques :

- AmazonEKSClusterPolicy
- AmazonEKSServicePolicy
- AmazonEKSVPCResourceController
- AmazonEKS_CNI_Policy

## üñ• D√©ploiement Local avec Docker Desktop

### Pr√©requis
- Docker Desktop install√©
- Kubernetes activ√© dans Docker Desktop (avec kubeadm)
- kubectl install√© (`brew install kubectl`)

### 1. Configuration de Kubernetes dans Docker Desktop
1. Ouvrir Docker Desktop
2. Aller dans Settings > Kubernetes
3. S√©lectionner "Enable Kubernetes"
4. Choisir "kubeadm" comme m√©thode de provisionnement
5. Cliquer sur "Apply & Restart"

### 2. Construction de l'Image
```bash
# Construire l'image localement
docker build -t goofy-cdn:local -f docker/cdn/Dockerfile .
```

### 3. D√©ploiement sur Kubernetes Local

1. **V√©rifier que kubectl utilise le bon contexte** :
```bash
# Voir les contextes disponibles
kubectl config get-contexts

# Passer au contexte Docker Desktop si n√©cessaire
kubectl config use-context docker-desktop
```

2. **D√©ployer l'application** :
```bash
# Appliquer les configurations
kubectl apply -f k8s/cdn-deployment.yaml
kubectl apply -f k8s/cdn-service.yaml

# V√©rifier le d√©ploiement
kubectl get pods
kubectl get services
```

### 4. Acc√®s √† l'Application

L'application est accessible via les endpoints suivants :
- **URL Principale** : `http://localhost:80`
- **M√©triques** : `http://localhost:80/metrics`
- **Health Check** : `http://localhost:80/health`
- **Readiness** : `http://localhost:80/ready`

### 5. Commandes Utiles

```bash
# Voir les logs de l'application
kubectl logs -l app=goofy-cdn

# Voir les d√©tails du pod
kubectl describe pod -l app=goofy-cdn

# Red√©marrer le d√©ploiement (apr√®s modification du code)
kubectl delete pod -l app=goofy-cdn

# Supprimer le d√©ploiement
kubectl delete -f k8s/cdn-deployment.yaml
kubectl delete -f k8s/cdn-service.yaml
```

### 6. Troubleshooting

#### Pod en CrashLoopBackOff ou Error
```bash
# Voir les logs du pod
kubectl logs -l app=goofy-cdn

# Voir les d√©tails et √©v√©nements du pod
kubectl describe pod -l app=goofy-cdn
```

#### Service inaccessible
1. V√©rifier que le service est bien cr√©√© :
```bash
kubectl get services
```

2. V√©rifier que le pod est Ready :
```bash
kubectl get pods -l app=goofy-cdn
```

3. Voir les endpoints :
```bash
kubectl get endpoints goofy-cdn-service
```

#### Probl√®mes d'image
Si l'image n'est pas trouv√©e, assurez-vous que :
1. L'image est bien construite localement : `docker images | grep goofy-cdn`
2. Le fichier deployment.yaml utilise le bon nom d'image : `image: goofy-cdn:local`
